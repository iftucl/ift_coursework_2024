"""
LlamaExtractor module for parsing sustainability reports using the LlamaParse API.

This module defines an asynchronous class to extract key environmental metrics
such as Scope emissions, energy consumption, and water usage from PDF reports.

Requires: llama-parse, loguru, pydantic, dotenv
"""
import os
import re
import json
import asyncio
from datetime import datetime
from dotenv import load_dotenv
from llama_parse import LlamaParse
from loguru import logger
from pydantic import BaseModel

# Load environment variables
load_dotenv(override=True)
LLAMA_API_KEY = os.getenv("LLAMA_API_KEY")

class LlamaExtractor(BaseModel):
    """
    Asynchronous extractor for sustainability metrics (Scope emissions, energy, water)
    from a filtered PDF using the LlamaParse API.
    """
    api_key: str = LLAMA_API_KEY
    company_name: str
    filtered_pdf_path: str

    async def process(self) -> dict:
        logger.info(f"ðŸ” Processing {self.company_name}")

        scope_data = await self.extract_scope_emissions(self.filtered_pdf_path, self.company_name)
        logger.info(f"Scope data: {json.dumps(scope_data, indent=2)}")

        energy_data = await self.extract_energy_metrics(self.filtered_pdf_path, self.company_name)
        logger.info(f"Energy data: {json.dumps(energy_data, indent=2)}")

        water_data = await self.extract_water_metrics(self.filtered_pdf_path, self.company_name)
        logger.info(f"Water data: {json.dumps(water_data, indent=2)}")

        return {
            "Scope Data": scope_data,
            "Energy Data": energy_data,
            "Water Data": water_data,
        }

    async def extract_scope_emissions(self, pdf_file: str, company_name: str) -> dict:
        return await self._extract_with_instruction(
            pdf_file,
            company_name,
            "Extract the following emissions metrics for all financial years available:\n"
            "- Scope 1 emissions (total)\n"
            "- Scope 2 emissions (market-based)\n"
            "- Scope 2 emissions (location-based)\n"
            "\nProvide a JSON structure like:\n"
            "{\n  \"Scope 1\": {\"2020\": [value, unit], \"2021\": [value, unit]}, ...\n}",
        )

    async def extract_energy_metrics(self, pdf_file: str, company_name: str) -> dict:
        return await self._extract_with_instruction(
            pdf_file,
            company_name,
            "Extract the following energy metrics for all financial years available:\n"
            "- Energy consumption (total, renewable, non-renewable)\n"
            "\nProvide a JSON structure like:\n"
            "{\n  \"Total Energy\": {\"2020\": [value, unit], \"2021\": [value, unit]}, ...\n}",
        )

    async def extract_water_metrics(self, pdf_file: str, company_name: str) -> dict:
        return await self._extract_with_instruction(
            pdf_file,
            company_name,
            "Extract the following water-related metrics for all financial years available:\n"
            "- Water usage or intensity (withdrawal, consumption, or any other relevant metrics)\n"
            "\nProvide a JSON structure like:\n"
            "{\n  \"Water Usage\": {\"2020\": [value, unit], \"2021\": [value, unit]}, ...\n}",
        )

    async def _extract_with_instruction(self, pdf_file: str, company_name: str, instruction: str) -> dict:
        try:
            parser = LlamaParse(
                api_key=self.api_key,
                result_type="markdown",
                verbose=False,
                language="en",
                num_workers=4,
                table_extraction_mode="full",
                parsing_instruction=f"This is a corporate sustainability report.\n\n{instruction}",
                is_formatting_instruction=True,
            )

            documents = await parser.aload_data(
                pdf_file,
                extra_info={
                    "file_name": f"{company_name}.pdf",
                    "processed_date": datetime.now().isoformat(),
                },
            )
            return self._extract_best_json_block(documents)

        except Exception as e:
            logger.error(f"Error during extraction for {company_name}: {e}")
            return {}

    def _extract_best_json_block(self, documents: list) -> dict:
        code_fence_pattern = re.compile(r"â â€¯ json\s*(.*?) â€¯â ", re.DOTALL | re.IGNORECASE)
        best_data = {}
        max_score = 0

        for doc in documents:
            content = doc.get_content()
            if not content:
                continue

            json_blocks = code_fence_pattern.findall(content)
            for block in json_blocks:
                try:
                    data = json.loads(block.strip())
                except Exception as exc:
                    logger.warning(f"Failed to parse JSON block: {exc}")
                    continue

                score = sum(
                    1 for values in data.values()
                    if isinstance(values, dict)
                    for year_val in values.values()
                    if isinstance(year_val, list) and len(year_val) == 2 and all(year_val)
                )

                if score > max_score:
                    best_data = data
                    max_score = score
                    logger.debug(f"ðŸ“Š New best data found with score: {score}")

        return best_data

# Example usage
if __name__ == "__main__":
    async def main():
        company = "NVIDIA"
        pdf_path = "filtered_report.pdf"

        extractor = LlamaExtractor(
            api_key=LLAMA_API_KEY,
            company_name=company,
            filtered_pdf_path=pdf_path,
        )
        result = await extractor.process()
        print(json.dumps(result, indent=2))

    asyncio.run(main())