
---

# ğŸ“„ Project README (Containerized & Poetry-Managed Version)  
# End-to-End Data Product Development for CSR Indicators: Extraction, Storage, and Visualization

---

# ğŸ“„ Project Process Image
![Project Overall Process](https://github.com/Etainos/ift_coursework_2024/blob/team_jacaranda/team_jacaranda/coursework_two/static/Project_Process.jpg)

---
## âš¡ Quick Start

Run the entire stack with:

```bash
docker compose up --build
```

> Then, access the frontend at: [https://csr.jacaranda.ngrok.app/](https://csr.jacaranda.ngrok.app/)

---

## ğŸ“Œ Project Overview
This project delivers an **end-to-end data product** for CSR indicators, covering:

- Extraction of sustainability (CSR) indicators from corporate reports
- Standardized storage in a database
- Visualization via a frontend interface

All components are fully containerized, with backend dependencies managed by **Poetry**.

---

## âš™ï¸ Environment Requirements
- Docker & Docker Compose
- Poetry â‰¥ 1.5.0
- Node.js â‰¥ 16 (for frontend development)
- Python â‰¥ 3.8 (managed via Poetry)
- PostgreSQL (in container)
- MinIO storage service (in container)

---

## ğŸ“‚ Project Structure
```
coursework_two/
 â”œâ”€â”€ config/                 # Configuration files (DB/MinIO connections)
 â”œâ”€â”€ FastAPI/                 # Backend API (FastAPI service)
 â”œâ”€â”€ modules/
 â”‚    â”œâ”€â”€ data_storage/       # Data extraction and processing
 â”‚    â”œâ”€â”€ db/                 # Database connection modules
 â”‚    â”œâ”€â”€ frontend/           # React frontend
 â”‚    â””â”€â”€ __init__.py
 â”œâ”€â”€ static/                  # Static assets
 â”œâ”€â”€ test/                    # Test scripts
 â”œâ”€â”€ .env                     # Environment variables
 â”œâ”€â”€ Dockerfile.txt           # Dockerfile (container setup)
 â”œâ”€â”€ pyproject.toml           # Poetry dependency configuration
 â”œâ”€â”€ poetry.lock
 â”œâ”€â”€ pytest.ini               # Pytest settings
 â””â”€â”€ .gitignore
```

---

## ğŸš€ Deployment & Startup Guide

### 1. Clone the Project
```bash
git clone <your-repo-url>
cd coursework_two
```

### 2. Install Python Dependencies via Poetry
```bash
poetry install
```

### 3. Configure Environment Variables
Create a `.env` file:
```
DEEPSEEK_API_KEY = sk-f3***************
```

### 4. Build and Start Containers
```bash
docker compose up --build
```

> ğŸ“Œ Note: This assumes the database is launched in a separate container.

---

## ğŸ› ï¸ Backend Data Processing Workflow

Activate the Poetry environment and run:

```bash
poetry shell
```

Execute step-by-step scripts:
```bash
poetry run python modules/data_storage/create_table.py
poetry run python modules/data_storage/paragraph_extraction.py
poetry run python modules/data_storage/retry_failed_reports.py
poetry run python modules/data_storage/llm_analyse.py
poetry run python modules/data_storage/llm_standardize.py
poetry run python modules/data_storage/data_export.py
```
Or run the full pipeline with:
```bash
poetry run python modules/data_storage/main.py
```

---

## ğŸ”— Backend API (FastAPI)

Start the FastAPI server:
```bash
poetry run uvicorn FastAPI.main:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ¨ Frontend Development and Production Build

### Development Mode
```bash
cd modules/frontend
npm install
npm start
```
Access the frontend at: [https://csr.jacaranda.ngrok.app/]

### Production Build
```bash
npm run build
```

---

## âœ¨ Project Highlights
- ğŸ“‘ End-to-end pipeline: PDF extraction â” Indicator extraction â” Unit standardization â” Database storage â” Frontend visualization
- âš¡ LLM-enhanced intelligent processing (text understanding and unit standardization)
- ğŸ³ Fully containerized deployment for maximum environment consistency
- ğŸ“¦ Centralized dependency management via Poetry
- ğŸ” Full test coverage with pytest

---
